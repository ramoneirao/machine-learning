{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33041a36",
   "metadata": {},
   "source": [
    "# **Normalizando Dados**\n",
    "Este notebook é dedicado ao estudo de técnicas de pré-processamento de dados, com foco na normalização utilizando as seguintes funções da biblioteca scikit-learn:\n",
    "\n",
    "- **Normalizer**: Normaliza os dados para que cada amostra tenha norma unitária.\n",
    "- **MinMaxScaler**: Escala os dados para um intervalo definido (por padrão, entre 0 e 1).\n",
    "- **StandardScaler**: Padroniza os dados para que tenham média 0 e desvio padrão 1.\n",
    "- **MaxAbsScaler**: Escala os dados para o intervalo [-1, 1] com base no valor absoluto máximo.\n",
    "\n",
    "O objetivo é compreender como essas técnicas podem ser aplicadas para preparar os dados antes de treinar modelos de machine learning, garantindo melhor desempenho e estabilidade nos resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351bf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5f50e",
   "metadata": {},
   "source": [
    "## MinMaxScaler\n",
    "\n",
    "O **MinMaxScaler** é uma técnica de normalização que transforma os dados para que fiquem dentro de um intervalo definido, geralmente entre 0 e 1. Essa técnica é útil quando queremos garantir que todas as variáveis tenham a mesma escala, especialmente em algoritmos sensíveis à magnitude dos dados, como redes neurais e métodos baseados em distância.\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "A transformação é realizada utilizando a seguinte equação:\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} \\cdot (max - min) + min\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- \\( X \\) é o valor original.\n",
    "- \\( X_{\\text{min}} \\) e \\( X_{\\text{max}} \\) são os valores mínimo e máximo da variável.\n",
    "- \\( min \\) e \\( max \\) são os limites inferior e superior do intervalo desejado (por padrão, 0 e 1).\n",
    "\n",
    "### Exemplo de aplicação\n",
    "\n",
    "Ao aplicar o MinMaxScaler, os valores originais são escalados proporcionalmente para o intervalo definido, preservando a relação entre eles. Isso é especialmente útil para evitar que variáveis com valores maiores dominem o treinamento de modelos de machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b953848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75       0.         0.         0.5       ]\n",
      " [0.         0.33333333 1.         1.        ]\n",
      " [1.         1.         0.42857143 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "print(normalizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae67d5",
   "metadata": {},
   "source": [
    "## StandardScaler\n",
    "\n",
    "O **StandardScaler** é uma técnica de padronização que transforma os dados para que tenham média 0 e desvio padrão 1. Essa técnica é especialmente útil em algoritmos de machine learning que assumem que os dados estão centrados na origem e com variância igual, como regressão logística, SVM e PCA.\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "A padronização é feita com base na seguinte fórmula:\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- \\( X \\) é o valor original.\n",
    "- \\( \\mu \\) é a média dos valores da variável.\n",
    "- \\( \\sigma \\) é o desvio padrão da variável.\n",
    "\n",
    "Essa transformação resulta em uma distribuição com média zero e variância unitária.\n",
    "\n",
    "### Exemplo de aplicação\n",
    "\n",
    "Ao aplicar o StandardScaler, todos os atributos passam a ter a mesma escala em termos de dispersão (desvio padrão), o que pode melhorar o desempenho de modelos que utilizam operações baseadas em distância ou que são sensíveis à distribuição dos dados. Ao contrário do MinMaxScaler, o StandardScaler não restringe os dados a um intervalo fixo, mas sim à dispersão estatística da distribuição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc2715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.39223227 -1.06904497 -1.16247639  0.        ]\n",
      " [-1.37281295 -0.26726124  1.27872403  1.22474487]\n",
      " [ 0.98058068  1.33630621 -0.11624764 -1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "print(standardizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbd619",
   "metadata": {},
   "source": [
    "## MaxAbsScaler\n",
    "\n",
    "O **MaxAbsScaler** é uma técnica de normalização que escala os dados com base no valor absoluto máximo de cada variável, transformando os dados para o intervalo \\([-1, 1]\\). Essa técnica é particularmente útil para dados que já estão centrados em zero ou que possuem muitos valores esparsos, como em tarefas com dados de texto vetorizados (ex.: TF-IDF).\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "A transformação é feita com a seguinte equação:\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X}{|X_{\\text{max}}|}\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- \\( X \\) é o valor original.\n",
    "- \\( |X_{\\text{max}}| \\) é o valor absoluto máximo da variável.\n",
    "\n",
    "Essa transformação preserva a sparcidade (zeros nos dados) e não centraliza os dados na média.\n",
    "\n",
    "### Exemplo de aplicação\n",
    "\n",
    "Ao aplicar o MaxAbsScaler, cada valor é dividido pelo maior valor absoluto da sua respectiva variável, garantindo que todos os dados fiquem no intervalo \\([-1, 1]\\). É ideal para algoritmos que se beneficiam de dados escalados, mas que não precisam que os dados sejam centrados em zero, como classificadores lineares aplicados a grandes conjuntos de dados esparsos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69d604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8        0.14285714 0.22222222 0.66666667]\n",
      " [0.2        0.42857143 1.         1.        ]\n",
      " [1.         1.         0.55555556 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "normalizer = MaxAbsScaler()\n",
    "print(normalizer.fit_transform(X))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97a31c",
   "metadata": {},
   "source": [
    "## **Normalizer**\n",
    "\n",
    "O `Normalizer` do `scikit-learn` oferece três modos de normalização: **L1**, **L2** e **Max**. Cada um define uma maneira diferente de escalar os vetores (linhas) para controlar sua magnitude.\n",
    "\n",
    "### L1 Normalization\n",
    "\n",
    "Na normalização **L1**, cada vetor é escalado para que a **soma dos valores absolutos** seja igual a 1.\n",
    "\n",
    "$$\n",
    "X_{\\text{normalized}} = \\frac{X}{\\|X\\|_1} = \\frac{X}{\\sum_i |x_i|}\n",
    "$$\n",
    "\n",
    "### L2 Normalization\n",
    "\n",
    "Na normalização **L2**, o vetor é escalado para que sua **norma euclidiana (comprimento)** seja 1.\n",
    "\n",
    "$$\n",
    "X_{\\text{normalized}} = \\frac{X}{\\|X\\|_2} = \\frac{X}{\\sqrt{\\sum_i x_i^2}}\n",
    "$$\n",
    "\n",
    "### Max Normalization\n",
    "\n",
    "Na normalização **Max**, os valores de cada vetor são divididos pelo **valor absoluto máximo** da linha:\n",
    "\n",
    "$$\n",
    "X_{\\text{normalized}} = \\frac{X}{\\max(|x_i|)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "229c429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44444444 0.11111111 0.22222222 0.22222222]\n",
      " [0.0625     0.1875     0.5625     0.1875    ]\n",
      " [0.27777778 0.38888889 0.27777778 0.05555556]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize com l1\n",
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "normalizer = Normalizer(norm='l1')\n",
    "X_normalized = normalizer.transform(X)\n",
    "print(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "382bea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8 0.2 0.4 0.4]\n",
      " [0.1 0.3 0.9 0.3]\n",
      " [0.5 0.7 0.5 0.1]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize com l2\n",
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "normalizer = Normalizer(norm='l2')\n",
    "X_normalized = normalizer.transform(X)\n",
    "print(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236c92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.25       0.5        0.5       ]\n",
      " [0.11111111 0.33333333 1.         0.33333333]\n",
      " [0.71428571 1.         0.71428571 0.14285714]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize com max\n",
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "normalizer = Normalizer(norm='max')\n",
    "X_normalized = normalizer.transform(X)\n",
    "print(X_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
